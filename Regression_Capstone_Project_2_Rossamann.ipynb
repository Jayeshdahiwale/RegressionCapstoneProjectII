{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "PH-0ReGfmX4f",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "JcMwzZxoAimU",
        "8G2x9gOozGDZ",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Rosamann Retails Sales Prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n",
        "##### **Member 1 -**  - Jayesh Prakash Dahiwale\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rossmann operates over 3,000 drug stores in 7 european countries. So our porject aim is to predict their daily sales for upto six weeks in advance. Stores sales are influenced by many factors, including promotions, competitions,school and state holidays, seasonality and locality. So In this project we have been provided the data from 1,500 Rossmann stores. So our task is to forecast the \"Sales\" column for the test** \n",
        "##<p>Provided there are two datasets, one is **Store** dataset having <b>1,115</b> observations in it with <b>10</b> columns and It gives us static information about each store such as the model and assortment of the store, information about the nearest competitor store, and whether or not they participate in the consecutive promotion \"Promo2\". Largely we're looking at numerical and date data, but Store Type and Assortment are flagged with letters to indicate store models and assorment level, per the variable explanations, as well as the PromoInterval column listing abbreviated months.</p>\n",
        "## <p>Other datatset is about **Sales** dataset having <b>1,017,209</b> observations in it with <b>9</b> columns and It gives us static information about each store such as the model and assortment of the store, information about the nearest competitor store, and whether or not they participate in the consecutive promotion \"Promo2\". Largely we're looking at numerical and date data, but Store Type and Assortment are flagged with letters to indicate store models and assorment level, per the variable explanations, as well as the PromoInterval column listing abbreviated months.</p>"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/Jayeshdahiwale/RegressionCapstoneProjectII"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DataSet Link -**"
      ],
      "metadata": {
        "id": "d1GjmOWgPlgc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Dataset DriveLink:https://drive.google.com/drive/folders/1XtTzgmtM-e9jGHbIq8pLzIbo3C8NF1T2?usp=share_link"
      ],
      "metadata": {
        "id": "sliViF0jPtgu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## **Questions for analysis are as follows**\n",
        "**1) Visualising the distribution of \"Sales\" & \"Customers\"?**<br>\n",
        "**2) Statistics of Sales column ?** <br>\n",
        "**3) Which rows are unnecessary and need to be removed ??** <br>\n",
        "**4) What are the outliers ?** <br>\n",
        "**5) Establishing relationship between Sales and Customers ?** <br>\n",
        "**6) How stores are performing in Sales by month based on Assortment type ?**<br>\n",
        "**7) How UPT metric compares across stores of different assortment types ?**<br>\n",
        "**8)Correlation between competition distance and UPT metric?**<br>\n",
        "**9)Which linear regression model is best?**<br>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Define Your Business Objective?**"
      ],
      "metadata": {
        "id": "PH-0ReGfmX4f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Increase the number of sales by predicting the rates at at optimal rate and finding the best suitalbe condition which attract the customers thereby increasing the profit for the Drug Store."
      ],
      "metadata": {
        "id": "PhDvGCAqmjP1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Importing the required packages**"
      ],
      "metadata": {
        "id": "IkikXoI50aJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import math"
      ],
      "metadata": {
        "id": "ugsJi7bk0gss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll begin with the required libraries and reading our .csv files"
      ],
      "metadata": {
        "id": "L1NCSUaZ5m8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount the google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "cgIqljBG1PCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the dataset file\n",
        "# dataset file googgle drive link : https://drive.google.com/file/d/185htr6OyxAZ0xb9QwxHpsUn8eTlq58v5/view?usp=share_link\n",
        "working_directory_path = '/content/drive/MyDrive/MachineLearningAlmabetterJourney/CapstoneProject2/'\n",
        "\n"
      ],
      "metadata": {
        "id": "7fIvHBHO2v1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_lookup = pd.read_csv(working_directory_path + 'store.csv')"
      ],
      "metadata": {
        "id": "nbTCYrN01D57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_data = pd.read_csv(working_directory_path + 'Rossmann Stores Data.csv')\n"
      ],
      "metadata": {
        "id": "TDx_ehdI5_c_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_lookup.head()"
      ],
      "metadata": {
        "id": "oVhpTAQY3zXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_lookup.shape"
      ],
      "metadata": {
        "id": "ivc5bzQD4OQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_lookup.info()"
      ],
      "metadata": {
        "id": "OH-7vhpq4m26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def null_cols(data):\n",
        "  columns = data.columns\n",
        "  null_cols = [(col,data[col].isna().sum()) for col in columns if data[col].isna().sum()!=0]\n",
        "  return null_cols"
      ],
      "metadata": {
        "id": "MsDr_CsU7Zms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "null_cols(store_lookup)"
      ],
      "metadata": {
        "id": "dhFOywrH7rCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see in store lookup table there are total 6 null columns"
      ],
      "metadata": {
        "id": "bqGg-I-U-MQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets see the sales data\n",
        "sales_data.head()"
      ],
      "metadata": {
        "id": "Vt5JHiIY-uoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_data.shape"
      ],
      "metadata": {
        "id": "dUDiYrYr-8QQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_data.info()"
      ],
      "metadata": {
        "id": "TMUEClAO-_8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These is no null columns in this dataset"
      ],
      "metadata": {
        "id": "5dWEI5wv_Gex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#lets see the starting date and end date of sales data\n",
        "print(sales_data['Date'].min())\n",
        "print(sales_data['Date'].max())"
      ],
      "metadata": {
        "id": "dOQ6bWN__PU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now we will merge the two data resources so we can more easily work with them. We will join the tables baes on the shared store column, which is a foreign key in the sales_data table and primary key in the stores_llokup table, so we'll validate the merge baed on this many to one relationship**"
      ],
      "metadata": {
        "id": "qRy7n95s_lN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_sales = sales_data.merge(store_lookup,how='left',on='Store',validate = 'many_to_one')"
      ],
      "metadata": {
        "id": "yM_V7eZqATXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_sales.info()"
      ],
      "metadata": {
        "id": "KRFeGVDlIojl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_sales.shape"
      ],
      "metadata": {
        "id": "gqOKzdKSB8lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_sales.head()"
      ],
      "metadata": {
        "id": "JCFl4bFzMPaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_sales.describe()"
      ],
      "metadata": {
        "id": "xJw-MQdnCOmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_sales.info()"
      ],
      "metadata": {
        "id": "ob3yKZ5uLQbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lets check the skewness of columns i.e.** <br>\n",
        " \"Day of Week\",\"Sales\",\"Customers\",\"Competion Distance\""
      ],
      "metadata": {
        "id": "bHxk_MpzI8dj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_sales[['DayOfWeek','Sales','Customers','CompetitionDistance']].skew()"
      ],
      "metadata": {
        "id": "CcfRnJIQKJxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can see here competition distance,customers are positively skewed<br>\n"
      ],
      "metadata": {
        "id": "4VK1MjEOKmLl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **<p>Lets check the distribution bell peak using kurotsis</p>**"
      ],
      "metadata": {
        "id": "L-PRyyVeLYgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_sales[['DayOfWeek','Sales','Customers','CompetitionDistance']].kurtosis()"
      ],
      "metadata": {
        "id": "TtquasIbLhsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the that competition distance,and customers has highest peak...And sales and Day of week has negative kurtosis"
      ],
      "metadata": {
        "id": "bWvGhQPgL0Y8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 1: Visualising the distribution of Sales and Customer columns**"
      ],
      "metadata": {
        "id": "zS0D0aA1akS-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **<p>Lets visualize the skewness and kurtosis</p>**"
      ],
      "metadata": {
        "id": "bb0kQwrv5WON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig,axes = plt.subplots(1,2)\n",
        "sns.distplot(merged_sales['Sales'],color=\"y\",ax=axes[0])\n",
        "sns.distplot(merged_sales['Customers'],color=\"y\",ax=axes[1])\n",
        "fig.set_size_inches(15,5)"
      ],
      "metadata": {
        "id": "OYhQqdj-5l5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Histograms of our Sales and Customers values show us a positive skew and high kurtosis."
      ],
      "metadata": {
        "id": "30rQSrXzOGIL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 2: Statistics of Sales column**"
      ],
      "metadata": {
        "id": "rcbs2CCkbnlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <p>**Next we will take a closer look at our statistics for sales column.**</p>"
      ],
      "metadata": {
        "id": "GM-b0tApOq_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"skew     \" + str(round(merged_sales['Sales'].skew(),6)))\n",
        "print(\"kurtosis \" + str(round(merged_sales['Sales'].kurtosis(),6)))\n",
        "print(merged_sales['Sales'].describe().round(3))\n",
        "print(\"mode     \" + str(merged_sales['Sales'].mode()))"
      ],
      "metadata": {
        "id": "3NmGtQq1O8X4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see our sales figures have a slightly positive skew, with the **mean (5773.819)** only slightly larger than the **median (5744.000)**, suggesting most outliers are to the right of the mean.\n",
        "\n",
        "High kurtosis indicates it's **leptokurtic** with the likelihood of heavy tails and outliers that may be extreme. Considering our min and max values of **0** and **41,551** sales, we aren't surprised to see there may be some extreme outliers.\n",
        "\n",
        "The max value well above the mean of 5,773.819 and outside the **standard deviation of 3849.926** helps us see how our mean ends up getting pulled slightly to the right for our positive skew.\n",
        "\n",
        "There is no mode as we don't have any stores recording the exact same number of sales on any days, which isn't surprising."
      ],
      "metadata": {
        "id": "Nl2yf2NJShUR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning"
      ],
      "metadata": {
        "id": "SWrvO0PGpxBM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<p>Datetime</p>"
      ],
      "metadata": {
        "id": "u8buzmTbT2Ur"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we'll convert our Date column to datetime for easier filtering later on.\n",
        "\n",
        "With an .info() call we can confirm our Date column was successfully converted to datetime.\n",
        "\n",
        "We'll also expand our Date column into separate Month, Day of Month, and Year columns for easier filtering."
      ],
      "metadata": {
        "id": "-sTgcfcNULew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_sales['Date'] = pd.to_datetime(merged_sales['Date'], format=\"%Y-%m-%d\", errors='raise')"
      ],
      "metadata": {
        "id": "xsXmKAPEbiL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_sales.info()"
      ],
      "metadata": {
        "id": "axALhlqNbuko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_sales[\"Year\"] = merged_sales[\"Date\"].dt.year\n",
        "merged_sales[\"Month\"] = merged_sales[\"Date\"].dt.month\n",
        "merged_sales[\"DayOfMonth\"] = merged_sales[\"Date\"].dt.day"
      ],
      "metadata": {
        "id": "R9c398fhl7H6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Duplicates**"
      ],
      "metadata": {
        "id": "O5SC3w9Imsh7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll do a quick check for and delete any rows that are complete duplicates of another row, as we should only have one entry for each store and date."
      ],
      "metadata": {
        "id": "-YU80oB1lx-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(merged_sales[merged_sales.duplicated()])"
      ],
      "metadata": {
        "id": "I77FQ-y4cw_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text and Expected Value**"
      ],
      "metadata": {
        "id": "XXeGNWbWcr5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_sales.loc[merged_sales['StateHoliday']==0,'StateHoliday'] = '0'"
      ],
      "metadata": {
        "id": "CkRQjPNDPyfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we'll check our four columns that contain strings to make sure we have no inappropriately entered data. Using str.strip() to remove any accidental leading or trailing spaces."
      ],
      "metadata": {
        "id": "ESRDnYAOrSzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in merged_sales:\n",
        "  \n",
        "  if merged_sales[col].dtype == object and col != 'StateHoliday':\n",
        "    merged_sales[col] = merged_sales[col].str.strip()"
      ],
      "metadata": {
        "id": "WHr2oWR8rhlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we'll look at value_counts for those columns and confirm only expected values are found."
      ],
      "metadata": {
        "id": "9WNe_ylDu2JX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in merged_sales:\n",
        "  if merged_sales[col].dtype==object:\n",
        "    print(merged_sales[col].value_counts().sort_index())"
      ],
      "metadata": {
        "id": "ZcrIs_IOvl4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_sales.info()"
      ],
      "metadata": {
        "id": "vvpcL_gmNclh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Everything is looking as expected in our columns that contain text, and because each column only has 3-4 unique values we can see we don't need to worry about changing anything to lower, upper, or proper case."
      ],
      "metadata": {
        "id": "U2DS3X8ufo05"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll also do a quick check of columns we expect to only have a few unique values or binary flags, such as DayOfWeek or Promo, to make sure there's nothing unexpected there."
      ],
      "metadata": {
        "id": "OVDCmEeAfs7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "check_cols = [ 'Open', 'Promo', 'Promo2', 'SchoolHoliday',  'DayOfWeek', 'CompetitionOpenSinceMonth',  'CompetitionOpenSinceYear', 'Promo2SinceWeek', 'Promo2SinceYear']\n",
        "for col in check_cols:\n",
        "    print(col)\n",
        "    print(sorted(merged_sales[col].unique()))"
      ],
      "metadata": {
        "id": "StfBkUYJng4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see the relevant binary flags, day of weeks, week, month, and year numeric values we expect.\n",
        "\n",
        "Because the CompetitionOpenSinceMonth, CompetitionOpenSinceYear, Promo2SinceWeek, and Promo2SinceYear columns are only using whole numbers and they are a discrete value, we will change them from floats to integers."
      ],
      "metadata": {
        "id": "UmTzgMBfga7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_sales['CompetitionOpenSinceMonth'] = merged_sales['CompetitionOpenSinceMonth'].convert_dtypes()\n",
        "merged_sales['CompetitionOpenSinceYear'] = merged_sales['CompetitionOpenSinceYear'].convert_dtypes()\n",
        "merged_sales['Promo2SinceWeek'] = merged_sales['Promo2SinceWeek'].convert_dtypes()\n",
        "merged_sales['Promo2SinceYear'] = merged_sales['Promo2SinceYear'].convert_dtypes()"
      ],
      "metadata": {
        "id": "n0712dLF0Z5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_sales.info()"
      ],
      "metadata": {
        "id": "Xz8wpTxHtEyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can see that CompetitionDistance, our only continuous value, is our only column with floats."
      ],
      "metadata": {
        "id": "HUC_iySlhNKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  **Question3):Removing rows and columns**"
      ],
      "metadata": {
        "id": "XrpOYlimhccD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below I look at entries for stores on days they were closed.\n",
        "\n",
        "For the purposes of our analysis I've chosen to drop these rows, as no sales are recorded on days stores are closed. The zero sales recorded for each of these rows lowers the average sales, and we can see this by comparing the mean Sales for all entries in our table to the mean Sales of only days that stores were open. If we filter for entries of stores that are closed we'll see a return of **172,817** rows, all of which record the expected 0 sales, lowering our mean Sales statistic.\n",
        "\n",
        "**The potential information lost here is if we want to compare stores based on the number of days they are open or closed**, but that is beyond the scope of our analysis for now. To avoid losing this information we will make a copy of our dataframe with only the days stores are open, to further be referred to as sales, rather than altering merged_sales in case we wish to access this data at a later time."
      ],
      "metadata": {
        "id": "UFNUqh_6tge1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## mean sales including entries for days stores are closed\n",
        "merged_sales['Sales'].mean()"
      ],
      "metadata": {
        "id": "FJevtCjmrkiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Not lets check the mean only for the data when the store is open\n",
        "merged_sales[merged_sales['Open']==1].Sales.mean()"
      ],
      "metadata": {
        "id": "ULvR_6ibru4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## confirming all entries where the store is  marked as closed have 0 sales\n",
        "merged_sales.loc[merged_sales[\"Open\"] == 0, ['Sales', 'Customers']].value_counts()\n"
      ],
      "metadata": {
        "id": "TqHvADQ7l9uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## creating new sales dataframe with only entries for days stores are open\n",
        "sales = merged_sales.drop(index=(merged_sales[merged_sales[\"Open\"] == 0]).index, axis=1)"
      ],
      "metadata": {
        "id": "DAezRm4ikPHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now as we chose to delete any rows for days a store wasn't open, our Open column should only contain the value 1 now and is redundant, so we'll remove that"
      ],
      "metadata": {
        "id": "wgVK8K2Tn3Zn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales.drop(columns=[\"Open\"], inplace=True)"
      ],
      "metadata": {
        "id": "qk0IiieMnTjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 4 : What are the outliers in the dataset ?**\n"
      ],
      "metadata": {
        "id": "nsDOoznDudq7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we'll take a look at any outliers we may need to treat."
      ],
      "metadata": {
        "id": "vbBxSyiuwjdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales.plot(y=['Sales', 'Customers', 'CompetitionDistance'], \n",
        "           kind='box', subplots=True, layout=(2,2), figsize=(15,15))"
      ],
      "metadata": {
        "id": "ju6buTsTwilP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the box plots above we can see that Sales, Customers, and CompetitionDistance all appear to have significant outliers, so we'll explore further by calculating and investigating the outliers for each one.\n"
      ],
      "metadata": {
        "id": "ftFnOAYl69JZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sales Outliers**\n",
        "\n"
      ],
      "metadata": {
        "id": "McXJZPey7PvI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will start with the Sales column."
      ],
      "metadata": {
        "id": "88iTmLQy7cXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_outlier(df,column): ## function for calculating outliers\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    IQR = Q3 - Q1\n",
        "    lower = Q1 - 1.5 * IQR\n",
        "    upper = Q3 + 1.5 * IQR\n",
        "    percent_outliers = round(((df[df[column] > upper].shape[0]) + (df[df[column] < lower].shape[0])) / df.shape[0] * 100, 2)\n",
        "    return lower, upper, percent_outliers"
      ],
      "metadata": {
        "id": "yh40DQzJz5oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col = 'Sales'\n",
        "lower_sales, upper_sales, percent_outliers_sales = calculate_outlier(sales, col)\n",
        "\n",
        "print(\"lower band = \" + str(lower_sales))\n",
        "print(\"upper band = \" + str(upper_sales))\n",
        "print(\"percentage of sales that are outliers = \" + str(percent_outliers_sales) + \"%\")\n",
        "print('Number of observations in which sales leass than <0 are '+str(len(sales[sales.Sales <0])))"
      ],
      "metadata": {
        "id": "mD7r7M_Y7-BM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We know from our summary statistics that there aren't any sales below 0, so we'll just look at the upper outliers that we've calculated for the Sales column."
      ],
      "metadata": {
        "id": "6a4VioXl9AQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales[sales[col] > upper_sales]"
      ],
      "metadata": {
        "id": "dRMsGC9c8-v4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "While 30,769 is a lot of values, we can see from our calculte_outlier function that these outliers only account for 3.64% of all our sales values.\n",
        "\n",
        "We'll look further to see if we see any trends with the outliers based on Month or Type of Store."
      ],
      "metadata": {
        "id": "YAonXm8m-g--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales_outliers_by_month = pd.pivot_table((sales.loc[sales[col] > upper_sales]), index='Month', values='Sales', aggfunc='count')\n",
        "\n",
        "sales_outliers_by_month.plot(y='Sales', kind='bar', figsize=(10,5), title=\"# of Sales Outlier Entries by Month\")\n",
        "plt.legend(loc='upper right', bbox_to_anchor=(1.2, 1.1))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZTEqSeek_Rdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_outliers_by_stype = pd.pivot_table((sales.loc[sales[col] > upper_sales]), index='StoreType', values='Sales', aggfunc='count')\n",
        "\n",
        "sales_outliers_by_stype.plot(y='Sales', kind='bar', figsize=(6,6), \n",
        "                             title=\"# of Sales Outlier Entries by Store Type\", \n",
        "                             color=['blue','red','green','orange'])\n",
        "plt.ylabel('Sales')\n",
        "plt.legend(loc='upper right', bbox_to_anchor=(1.2, 1.1))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zQPask_e_ric"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we look at the Sales outliers by month, we see the most represented month is **December at 17.33%**, which is unsurprising given the Christmas holidays. However, when we look at the outliers by Store Type we see that the **61.71% majority** are coming from **Type A stores**, while **Type B, C, D** are more equally represented at **11-15%**. This suggests that Type A stores may be the best performers in regards to outstanding sales days, and is worth looking into further.\n",
        "\n",
        "Below we will treat our Sales outliers by imputing them with our upper range value we calculated earlier, **13611.5**, rounded up to **13612** as our Sales column is a measure of discrete values using whole numbers. As these outliers represent exceptionally high sales day, they are intended to be high numbers, but we would like to treat the outliers to limit their influence on any future modelling. As such imputing with our upper range value feels more appropriate than using our mean Sales value.\n",
        "\n",
        "We also save this a new dataframe going forward, to further be referenced to as sales_treated, so that we can preserve our sales dataframe with the outliers intact, should we wish to investigate them further."
      ],
      "metadata": {
        "id": "wAfRRtWzBNwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales_treated = sales.copy()"
      ],
      "metadata": {
        "id": "R97QHxguDh6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_treated.loc[sales_treated[col] > upper_sales, 'Sales'] = 13612"
      ],
      "metadata": {
        "id": "p71tdj1iDmTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Further check whether our imputation worked or not"
      ],
      "metadata": {
        "id": "t7WqAoUhDxp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales_treated[sales_treated['Sales'] > 13612]"
      ],
      "metadata": {
        "id": "vC25dYv6DsFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Customer Outliers**"
      ],
      "metadata": {
        "id": "odTSly_50F8Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we'll calculate and investigate our Customer outliers."
      ],
      "metadata": {
        "id": "Io4mWZOYFBwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "col = 'Customers'\n",
        "lower_cust, upper_cust, percent_outliers_cust = calculate_outlier(sales_treated, col)\n",
        "\n",
        "print(str(lower_cust) + \", \" + str(upper_cust) +\", \" + str(percent_outliers_cust) + \"%\")\n",
        "print('Number of rows when customer < 0 : ' + str(len(sales[sales_treated['Customers']<0])))"
      ],
      "metadata": {
        "id": "XPM0V5zM0Y4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar to Sales, we know from our summary statistics that we don't have any Customer values below 0, so we'll just look at our upper range value."
      ],
      "metadata": {
        "id": "J5pGx4ksFseP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales_treated[sales_treated['Customers'] > upper_cust]"
      ],
      "metadata": {
        "id": "7WQ9qkEhrLJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We Can see right away that several of these entries have a **Sales value of 13,612**, which we know to be our newly imputed upper range value for Sales outliers. We expect a high correlation between Customers driving Sales, so we'll check to see how much crossover we have between our Sales and Customers outliers.\\"
      ],
      "metadata": {
        "id": "JsqwfsMkG2td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales_treated[(sales_treated['Customers'] > upper_cust) & (sales_treated['Sales'] == 13612)]"
      ],
      "metadata": {
        "id": "nc5gemo91G6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see a crossover of **21,420 rows**, or approximately **52%** of our Customer outlier entries are also Sales outlier entries.\n",
        "\n",
        "We will also investigate how these Customer outliers break down by Month and StoreType just as we did with our Sales outliers."
      ],
      "metadata": {
        "id": "krVzFB6dHJlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cust_outliers_by_month = pd.pivot_table((sales_treated.loc[sales_treated[col] > upper_cust]), index='Month', values='Customers', aggfunc='count')\n",
        "\n",
        "cust_outliers_by_month.plot(y='Customers', kind='bar', figsize=(10,5), title=\"# of Customer Outlier Entries by Month\")\n",
        "plt.legend(loc='upper right', bbox_to_anchor=(1.2, 1.1))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rBG30TWSw5p3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cust_outliers_by_stype = pd.pivot_table((sales_treated.loc[sales_treated[col] > upper_cust]), index='StoreType', values='Customers', aggfunc='count')\n",
        "\n",
        "cust_outliers_by_stype.plot(y='Customers', kind='bar', figsize=(6,6), \n",
        "                             title=\"# of Customer Outlier Entries by Store Type\", \n",
        "                             color=['blue','red','green','orange'])\n",
        "plt.legend(loc='upper right', bbox_to_anchor=(1.2, 1.1))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wLPPaqe4H2XV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**December** is our most represented month for Customer outliers, similar to our Sales outliers, but it's percentage of outliers is less than we saw with our Sales.\n",
        "\n",
        "We also see **store Type A** with the strongest showing when we break down the outliers by store type. Much like the Sales outliers **Type A stores** represent a **strong 60%+** of the outliers. Surprisingly, **Type D stores** represent a tiny **1.02%** of these Customer outliers, where as they represented the second largest percentage of Sales outliers at **15.29%**. Further investigation into the number of items bought (Sales) per transaction (Customer) may prove insightful.\n",
        "\n",
        "Similar to our Sales outliers, we will also limit our Customer outliers to our calculated upper range, by imputing them to **1,454,** so as to limit their influence but also indicate that they're meant to be high numbers."
      ],
      "metadata": {
        "id": "M5R5EBqf4V-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales_treated.loc[sales_treated['Customers'] > upper_cust, 'Customers'] = 1454"
      ],
      "metadata": {
        "id": "n2ygrKwS50ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_treated.loc[sales_treated['Customers'] > upper_cust, 'Customers']"
      ],
      "metadata": {
        "id": "6r23YgHn6dlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Missing Values**"
      ],
      "metadata": {
        "id": "u6KxEw2H6zWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we'll take a look at missing values. We'll start by assessing how many we have and where."
      ],
      "metadata": {
        "id": "7e_175Ay7cZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales_treated.isna().sum()"
      ],
      "metadata": {
        "id": "uxNtOrd17ikU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(sales_treated.isna().sum() * 100 / sales_treated.shape[0]).round(2)   ## missing values as a % of all values in the column"
      ],
      "metadata": {
        "id": "BMKHpJ63UnBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "While we see a rather high 50% missing values rate for Promo2SinceWeek and Promo2SinceYear we can check and see if these all just correspond to stores that aren't running Promo2, and hence would not be expected to have valid data for these columns."
      ],
      "metadata": {
        "id": "PkZD2kBw9WJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sales_treated[sales_treated['Promo2'] == 0].shape[0])\n",
        "print(sales_treated['Promo2SinceWeek'].isna().sum())\n",
        "print(sales_treated['Promo2SinceYear'].isna().sum())"
      ],
      "metadata": {
        "id": "c64Rd_FLU8gC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the number of entries with missing **Promo2SinceWeek** and **Promo2SinceYear** values corresponds with the number of entries where the store isn't participating in Promo2, we can rest assured that the lack of data here is appropriate.\n",
        "\n"
      ],
      "metadata": {
        "id": "iEhCN49DVjld"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The other area we see missing data is in relation to competition stores, mostly in the two columns relating when the nearest competitor store opened, and to much lesser extent in **CompetitionDistance**\n",
        "\n",
        "The CompetitionDistance values may be used for analyzing how stores perform based on how close their competition is, and as such missing values could skew such analysis. 0 would be an inappropriate replacement for these null values as it would indicate that the competition stores are incredibly close. As such we'll look to replace these missing values with the mean CompetitionDistance based on the StoreType."
      ],
      "metadata": {
        "id": "D_Nb-BN-Vl_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_type_a = round(store_lookup.loc[(store_lookup['StoreType'] == 'a'), 'CompetitionDistance'].mean(), 1)\n",
        "mean_type_b = round(store_lookup.loc[(store_lookup['StoreType'] == 'b'), 'CompetitionDistance'].mean(), 1)\n",
        "mean_type_c = round(store_lookup.loc[(store_lookup['StoreType'] == 'c'), 'CompetitionDistance'].mean(), 1)\n",
        "mean_type_d = round(store_lookup.loc[(store_lookup['StoreType'] == 'd'), 'CompetitionDistance'].mean(), 1)\n",
        "\n",
        "print(\"The mean Compeition Distance for stores of type A is \" + str(mean_type_a))\n",
        "print(\"The mean Compeition Distance for stores of type B is \" + str(mean_type_b))\n",
        "print(\"The mean Compeition Distance for stores of type C is \" + str(mean_type_c))\n",
        "print(\"The mean Compeition Distance for stores of type D is \" + str(mean_type_d))"
      ],
      "metadata": {
        "id": "RaGrCzqg-ul7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_treated.loc[sales_treated['StoreType'] == 'a'] = sales_treated.loc[sales_treated['StoreType'] == 'a'].fillna(value={\"CompetitionDistance\" : mean_type_a})\n",
        "sales_treated.loc[sales_treated['StoreType'] == 'b'] = sales_treated.loc[sales_treated['StoreType'] == 'b'].fillna(value={\"CompetitionDistance\" : mean_type_b}) \n",
        "sales_treated.loc[sales_treated['StoreType'] == 'c'] = sales_treated.loc[sales_treated['StoreType'] == 'c'].fillna(value={\"CompetitionDistance\" : mean_type_c}) \n",
        "sales_treated.loc[sales_treated['StoreType'] == 'd'] = sales_treated.loc[sales_treated['StoreType'] == 'd'].fillna(value={\"CompetitionDistance\" : mean_type_d}) "
      ],
      "metadata": {
        "id": "CN01dUKG_QDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_treated.isna().sum()"
      ],
      "metadata": {
        "id": "m7xZMl4QaOLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we will replace the null values in our PromoInterval column. As this column contains strings listing the months the Promo2 starts anew, we will replace the missing values with a string 'NA' for Not Applicable."
      ],
      "metadata": {
        "id": "6Bx27h56ibLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales_treated.loc[sales_treated['PromoInterval'].isna(), 'PromoInterval'] = \"NA\""
      ],
      "metadata": {
        "id": "sUugW7JSAXlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_treated['PromoInterval'].value_counts()"
      ],
      "metadata": {
        "id": "nFYJ5PPrBlPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the missing values in **'CompetitionOpenSinceYear'** & **'Promo2SinceYear'** it would be inappropriate to replace them with zeros, as further calculations with the years in that column could lead to values suggesting a competition store has been open **2022** years. As such, we'll impute these missing values with the current year, so if calculations are done to find how long the nearest competition store has been open since these instances of no competition store nearby will return zero years.\n",
        "\n",
        "In the same manner we will impute the missing values in **'CompetitionOpenSinceMonth'** with the **current month**, and 'Promo2SinceWeek' with the current week."
      ],
      "metadata": {
        "id": "xh0b1jyLi8IY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales_treated.loc[sales_treated['CompetitionOpenSinceYear'].isna(), 'CompetitionOpenSinceYear'] = dt.datetime.now().year\n",
        "\n",
        "sales_treated.loc[sales_treated['Promo2SinceYear'].isna(), 'Promo2SinceYear'] = dt.datetime.now().year\n",
        "\n",
        "sales_treated.loc[sales_treated['CompetitionOpenSinceMonth'].isna(), 'CompetitionOpenSinceMonth'] = dt.datetime.now().month\n",
        "\n",
        "sales_treated.loc[sales_treated['Promo2SinceWeek'].isna(), 'Promo2SinceWeek'] = dt.datetime.now().isocalendar()[1]"
      ],
      "metadata": {
        "id": "z382KVAIl3uO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets see the null counts\n",
        "sales_treated.isna().sum()"
      ],
      "metadata": {
        "id": "RPAqH4ZlD4ZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 5: Establising relationship between Sales and Customers ?**"
      ],
      "metadata": {
        "id": "78ur1XcNm80v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Adding an UPT column**"
      ],
      "metadata": {
        "id": "P3hilI_MEtKh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on our investigation of Sales and Costumers outliers, particularly how they're represented by different store types, I thought it would be worthwhile to add a calculated column to give us some insight into the relationship between Customers and Sales for each store and day."
      ],
      "metadata": {
        "id": "eVsvcm9sqG3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(sales_treated['Customers'] >= sales_treated['Sales']).value_counts()"
      ],
      "metadata": {
        "id": "pIVvd14eFQG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that for almost all entries we have in our dataframe, the number of Sales at a given store is greater than the number of Customers. Suggesting that the Customers value is derived by how many transactions there are at a store, and the Sales value is indicative of how many individual items are sold. Thus we can calculate the average number of items sold for each transaction as Units Per Transaction (UPT).\n",
        "\n",
        "First we'll quickly investigate the 54 rows where there aren't more Sales than Customers."
      ],
      "metadata": {
        "id": "NgSNO_pKqgRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales_treated[sales_treated['Customers'] >= sales_treated['Sales']]"
      ],
      "metadata": {
        "id": "Nsiu_-seH0iO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the majority of these days are entries with both zero Sales and zero Customers recorded. This seems odd for a day that the store is open. A quick check of merged_sales, which still has the Open column, gives us the same results and assures us that the stores are indeed marked as open on these days."
      ],
      "metadata": {
        "id": "jVIWaQQbKtMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_sales[(merged_sales['Customers'] >= merged_sales['Sales']) & merged_sales['Open'] == 1]"
      ],
      "metadata": {
        "id": "-nULPE4OK0UG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I can only speculate as to why we have entries for stores that are open but aren't recording any sales, perhaps a stocktake day? Let's also look at the cases that aren't zero Sales and zero Customers."
      ],
      "metadata": {
        "id": "2VHMuDPxLC3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales_treated[sales_treated['Customers'] > sales_treated['Sales']]"
      ],
      "metadata": {
        "id": "YwHHjv9HLI21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'm unsure of why we have two days with zero Sales and a small handful of Customers. As I have no explanation for these 2 days, nor the 52 other open days with zero Sales and Customers, I don't feel comfortable deleting them.\n",
        "\n",
        "This does pose a small problem for calculating our average UPT, however. As such we will create our UPT column by dividing the day's Sales by the days Customers to find the average Units Per Transaction for each day and store. The resulting 52 null values will be imputed with a zero to reflect the zero Sales for those entries."
      ],
      "metadata": {
        "id": "VLNesK-DLdLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales_treated['UPT'] = sales_treated['Sales'] / sales_treated['Customers']"
      ],
      "metadata": {
        "id": "nAei2LLmLh7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_treated['UPT'].isna().sum()"
      ],
      "metadata": {
        "id": "GG7dxouDr-aN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_treated.loc[sales_treated['UPT'].isna(), 'UPT'] = 0"
      ],
      "metadata": {
        "id": "MaPUOGiVsHBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_treated['UPT'].isna().sum()"
      ],
      "metadata": {
        "id": "i3-VMm2NsI16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll also add this UPT column to our sales table which still contains our Sales and Customers outliers, so we can explore the UPT with the outliers as well."
      ],
      "metadata": {
        "id": "DjgjiveTsUsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales['UPT'] = sales['Sales'] / sales['Customers']\n",
        "sales.loc[sales['UPT'].isna(), 'UPT'] = 0"
      ],
      "metadata": {
        "id": "sP7io__QsTwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Review of Summary Statistics Post Cleaning**"
      ],
      "metadata": {
        "id": "lZOY2DaSsiWE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's quickly review some of our summary statistics now that we've cleaned our data a bit. We can look at the summary statistics for sales to see them as they were before treating outliers and imputing for missing data, and compare them to the sales_treated summary statistics to see how they've changed."
      ],
      "metadata": {
        "id": "sIk7E_GSNJk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_sales[['Sales', 'Customers', 'CompetitionDistance']].describe() ## BEFORE cleaning\n"
      ],
      "metadata": {
        "id": "gfmzCJ6cSimq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_treated[['Sales', 'Customers', 'CompetitionDistance', 'UPT']].describe() ## AFTER cleaning"
      ],
      "metadata": {
        "id": "XtOu94JvSwYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the cleaning has narrowed our standard deviation for Sales and Customers, as well as raising the mean after removing the entries for closed stores."
      ],
      "metadata": {
        "id": "K3eRutlltLJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_sales[['Sales', 'Customers', 'CompetitionDistance']].skew() ## BEFORE cleaning"
      ],
      "metadata": {
        "id": "X5KP_ym9OwZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_treated[['Sales', 'Customers', 'CompetitionDistance', 'UPT']].skew() ## AFTER cleaning"
      ],
      "metadata": {
        "id": "4AwphE9IsOv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_sales[['Sales', 'Customers', 'CompetitionDistance']].kurtosis() ## BEFORE cleaning"
      ],
      "metadata": {
        "id": "RQ4azBb6Wmpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_treated[['Sales', 'Customers', 'CompetitionDistance', 'UPT']].kurtosis() ## AFTER cleaning"
      ],
      "metadata": {
        "id": "Gt7zQYBUwjro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,axes = plt.subplots(1,2)\n",
        "sns.distplot(sales_treated['Sales'],color=\"y\",ax=axes[0])\n",
        "sns.distplot(sales_treated['Customers'],color=\"y\",ax=axes[1])\n",
        "fig.set_size_inches(15,5)"
      ],
      "metadata": {
        "id": "6mDnx_jbuLOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Histograms of our Sales and Customers values shows us a slight positive skew, which changed a little after our cleaning, and we see a more significant change in kurtosis being lowered. We also see the effect of imputing our outliers with our upper range limit on the right side of either histogram.\n",
        "\n",
        " we now got results that are looking far closer to a standard normalization."
      ],
      "metadata": {
        "id": "93TCrEcqunl3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exploratory Insights**"
      ],
      "metadata": {
        "id": "4y8-zSAZZsew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Question 6: How stores perform in Sales by month based of Assortment type?**"
      ],
      "metadata": {
        "id": "MbWMtl8_50b-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's explore how stores perform in Sales by month, based on Assortment type. We know that Assortment type A offers a \"basic\" assortment of merchandise, Type B offers and \"extra\" assortment, and type C offers an \"extended\" assortment.\n",
        "\n",
        "Because our data ranges from Jan. 1, 2013 - July 31, 2015, we will exclude the 2015 data for now so as we are only looking at a complete years' worth of numbers."
      ],
      "metadata": {
        "id": "OntWsc3MvVjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assortment_pivot_total_sales = pd.pivot_table((sales_treated[sales_treated['Year'] < 2015]), ## Excluding 2015 data\n",
        "               index='Month', values='Sales', columns='Assortment', aggfunc=np.sum)\n",
        "assortment_pivot_total_sales"
      ],
      "metadata": {
        "id": "lpdUrvUdZytE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assortment_pivot_total_sales.plot(kind='line', title='Total Sales by Month and Store Assortment', figsize=(7,8), grid=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8oC7kBsIwfkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A quick look at Sales by volume of total sales shows that stores of Assortment types A and C have significantly more volume than type B stores. Type B stores stay fairly consistent in total Sales volume across all months, with minor upticks during mid-year and end year. Type A and C stores can be seen to follow very similar trends in terms of Sales volume.\n",
        "\n",
        "A quick look at how many stores we have of each Assortment type will show us significantly less stores of Assortment type B, which accounts for the significantly lower volume of Sales."
      ],
      "metadata": {
        "id": "6QPgLgzCwxUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.pivot_table((sales_treated[sales_treated['Year'] < 2015]), index='Assortment', values='Store', aggfunc='count')"
      ],
      "metadata": {
        "id": "TYtU3Sxma9Wk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to the vast differences in total Sales volume based on Assortment type, lets also look at the average number of Sales.\n",
        "\n",
        "(Note: We could include our 2015 data since we're calculating the mean Sales now, but for the sake of consistency when comparing it with the total Sales we will continue to use the same 2013-2014 data.)"
      ],
      "metadata": {
        "id": "bGFpU2BHdamc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assortment_pivot_avg_sales = pd.pivot_table((sales_treated[sales_treated['Year'] < 2015]), index='Month', values='Sales', columns='Assortment', aggfunc=np.mean)\n",
        "assortment_pivot_avg_sales"
      ],
      "metadata": {
        "id": "8u3VumVzc6VM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assortment_pivot_avg_sales.plot(kind='line', title='Average Sales by Month and Store Assortment', figsize=(7,5), grid=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EMxc0JWpo1QU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look at average Sales by store Assortment type we can see that stores of type B actually perform quite well when compared to types A and C, despite there being significantly less type B stores! Types A and C continue to follow very similar trends for Sales, but Type C stores consistently outperform type A stores.\n",
        "\n"
      ],
      "metadata": {
        "id": "AWezEoclyVxO"
      }
    }
  ]
}